{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d1451c",
   "metadata": {},
   "source": [
    "# Sistema Inteligente de Recuperación y Generación con LangChain\n",
    "\n",
    "### Alison Geraldine Valderrama Munar\n",
    "\n",
    "Implementación de un sistema **RAG (Retrieval-Augmented Generation)** que integra modelos de lenguaje avanzados con búsqueda semántica vectorial para consultas contextuales sobre contenido web técnico.\n",
    "\n",
    "**Tecnologías:** LangChain, OpenAI GPT-4o, Pinecone Vector DB, BeautifulSoup4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a22fe7d",
   "metadata": {},
   "source": [
    "## Configuración Inicial\n",
    "\n",
    "### Librerías Requeridas\n",
    "\n",
    "Instalación de componentes esenciales:\n",
    "- **openai, python-dotenv**: Integración con OpenAI y manejo de configuración\n",
    "- **langchain**: Orquestación de aplicaciones con LLMs\n",
    "- **langchain-openai, langchain-pinecone**: Conectores especializados\n",
    "- **bs4**: Extracción de contenido HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9401d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-text-splitters langchain-community bs4\n",
    "%pip install -qU langchain-openai\n",
    "%pip install -qU langchain-pinecone\n",
    "%pip install -q python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2b36f",
   "metadata": {},
   "source": [
    "### Variables de Entorno\n",
    "\n",
    "Importación de credenciales desde `.env`:\n",
    "- `OPENAI_API_KEY`: Acceso a GPT-4o y generación de embeddings\n",
    "- `PINECONE_API_KEY`: Autenticación en base de datos vectorial\n",
    "- `PINECONE_INDEX_NAME`: Nombre del índice destino\n",
    "- `LANGCHAIN_API_KEY`: Monitoreo con LangSmith (opcional)\n",
    "- `LANGCHAIN_TRACING`: Habilitación de trazas de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbde315b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno configurado correctamente.\n",
      "Claves cargadas: OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_INDEX_NAME\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Importar variables de entorno\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Verificación de claves obligatorias\n",
    "mandatory_vars = [\"OPENAI_API_KEY\", \"PINECONE_API_KEY\", \"PINECONE_INDEX_NAME\"]\n",
    "for var in mandatory_vars:\n",
    "    if not os.getenv(var):\n",
    "        raise ValueError(f\"Variable {var} no está definida en .env\")\n",
    "\n",
    "print(\"Entorno configurado correctamente.\")\n",
    "print(f\"Claves cargadas: {', '.join(mandatory_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d2f502",
   "metadata": {},
   "source": [
    "### Modelos de Inteligencia Artificial\n",
    "\n",
    "Inicialización de componentes IA:\n",
    "- **GPT-4o**: Motor de generación de respuestas conversacionales\n",
    "- **text-embedding-3-small**: Generador de representaciones vectoriales (512 dimensiones) para búsqueda semántica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e2abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Componentes IA listos.\n",
      "LLM: GPT-4o\n",
      "Embeddings: text-embedding-3-large (1024d)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Instanciar modelo conversacional\n",
    "chat_model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "# Instanciar generador de embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", dimensions=1024)\n",
    "\n",
    "print(\"Componentes IA listos.\")\n",
    "print(f\"LLM: GPT-4o\")\n",
    "print(f\"Embeddings: text-embedding-3-large (1024d)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e027e761",
   "metadata": {},
   "source": [
    "### Conexión a Pinecone\n",
    "\n",
    "Establecer conexión con el servicio de vectores:\n",
    "- Autenticación mediante API key\n",
    "- Acceso al índice preconfigurado (arep-taller)\n",
    "- Verificación de características del índice (512 dims, similitud coseno)\n",
    "- Creación del vector store para operaciones RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Conectar con Pinecone\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "idx_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "pc_index = pc.Index(idx_name)\n",
    "\n",
    "# Consultar metadatos del índice\n",
    "index_stats = pc_index.describe_index_stats()\n",
    "print(f\"Índice: {idx_name}\")\n",
    "print(f\"Dimensiones: {index_stats.get('dimension', 'N/A')}\")\n",
    "print(f\"Vectores actuales: {index_stats.get('total_vector_count', 0)}\")\n",
    "\n",
    "# Configurar almacén vectorial\n",
    "vector_db = PineconeVectorStore(embedding=embeddings, index=pc_index, )\n",
    "\n",
    "print(\"Conexión a Pinecone establecida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f3c1da",
   "metadata": {},
   "source": [
    "## 1. Fase de Indexación: Captura y Preparación de Datos\n",
    "\n",
    "### 1.1 Descarga de Contenido Web\n",
    "\n",
    "Obtención de documentación mediante `WebBaseLoader`:\n",
    "- **Origen**: Artículo técnico sobre agentes de IA\n",
    "- **Extractor**: BeautifulSoup filtra título, headers y texto principal\n",
    "- Generación de documento unificado con el contenido completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0421de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido web cargado\n",
      "Tamaño: 43,047 caracteres\n",
      "URL: https://lilianweng.github.io/posts/2023-06-23-agent/\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Definir filtros de extracción HTML\n",
    "html_filter = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": html_filter},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Contenido web cargado\")\n",
    "print(f\"Tamaño: {len(docs[0].page_content):,} caracteres\")\n",
    "print(f\"URL: {docs[0].metadata.get('source', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54388f2",
   "metadata": {},
   "source": [
    "### 1.2 Previsualización del Documento\n",
    "\n",
    "Muestra de los primeros 500 caracteres para verificar la calidad de la extracción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cdd83b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragmento inicial del contenido:\n",
      "================================================================================\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Fragmento inicial del contenido:\")\n",
    "print(\"=\" * 80)\n",
    "print(docs[0].page_content[:500])\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae65eba",
   "metadata": {},
   "source": [
    "### 1.3 Segmentación del Texto\n",
    "\n",
    "División del documento con `RecursiveCharacterTextSplitter`:\n",
    "- **Chunk size**: 1000 caracteres por segmento\n",
    "- **Overlap**: 200 caracteres de solapamiento contextual\n",
    "- **add_start_index**: Mantener referencia a posición original\n",
    "- Mejora la precisión en la recuperación de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92d3b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento dividido en 63 segmentos.\n",
      "Longitud promedio: 718 chars\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Crear divisor de texto\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Documento dividido en {len(chunks)} segmentos.\")\n",
    "print(f\"Longitud promedio: {sum(len(c.page_content) for c in chunks) // len(chunks)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64675083",
   "metadata": {},
   "source": [
    "### 1.4 Almacenamiento Vectorial\n",
    "\n",
    "Proceso de indexación:\n",
    "- Conversión de segmentos a vectores 1024D\n",
    "- Almacenamiento en Pinecone con metadata\n",
    "- Asignación de IDs únicos por fragmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf7e991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexados 63 fragmentos en Pinecone\n",
      "Muestra de IDs: ['c877389d-aec8-42cd-96b3-86c3360ec59e', 'bf57df7d-671e-443f-b22d-e508412049ae', '22de2f0c-d07b-449b-8ce2-b9e0e4bda79f']\n",
      "Base de datos actualizada\n"
     ]
    }
   ],
   "source": [
    "doc_ids = vector_db.add_documents(documents=chunks)\n",
    "\n",
    "print(f\"Indexados {len(doc_ids)} fragmentos en Pinecone\")\n",
    "print(f\"Muestra de IDs: {doc_ids[:3]}\")\n",
    "print(f\"Base de datos actualizada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a302a821",
   "metadata": {},
   "source": [
    "## 2. Motor RAG: Recuperación Contextual y Generación\n",
    "\n",
    "### 2.1 Tool de Búsqueda Contextual\n",
    "\n",
    "Función para recuperar información relevante:\n",
    "- Ejecuta búsqueda por similitud semántica\n",
    "- Obtiene los 2 documentos más cercanos (k=2)\n",
    "- Formatea resultados con metadata\n",
    "- Retorna contenido y objetos documento mediante `@tool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a561c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool de búsqueda creado\n",
      "Parámetros: k=2 documentos por query\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Busca y retorna contexto relevante para responder la pregunta del usuario.\"\"\"\n",
    "    results = vector_db.similarity_search(query, k=2)\n",
    "    context_str = \"\\n\\n\".join(\n",
    "        (f\"Metadata: {d.metadata}\\nTexto: {d.page_content}\")\n",
    "        for d in results\n",
    "    )\n",
    "    return context_str, results\n",
    "\n",
    "print(\"Tool de búsqueda creado\")\n",
    "print(\"Parámetros: k=2 documentos por query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ce764",
   "metadata": {},
   "source": [
    "### 2.2 Ensamblaje del Agente RAG\n",
    "\n",
    "Construcción del agente con `create_agent`:\n",
    "- Vinculación de GPT-4o con tool de búsqueda\n",
    "- Prompt de sistema para uso estratégico del contexto\n",
    "- Arquitectura que combina recuperación y generación\n",
    "- Soporte para búsquedas múltiples en queries complejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a58653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente RAG operacional\n",
      "Stack: GPT-4o + Pinecone Search\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "tools_list = [retrieve_context]\n",
    "\n",
    "# Prompt del sistema\n",
    "sys_prompt = (\n",
    "    \"Cuentas con una herramienta que recupera contexto de artículos técnicos. \"\n",
    "    \"Úsala de forma inteligente para dar respuestas bien fundamentadas. \"\n",
    "    \"Puedes hacer varias búsquedas si la pregunta lo requiere.\"\n",
    ")\n",
    "\n",
    "# Crear agente RAG\n",
    "agent = create_agent(chat_model, tools_list, system_prompt=sys_prompt)\n",
    "\n",
    "print(\"Agente RAG operacional\")\n",
    "print(\"Stack: GPT-4o + Pinecone Search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c129a",
   "metadata": {},
   "source": [
    "## 3. Prueba del Sistema\n",
    "\n",
    "Evaluación con query de múltiples pasos:\n",
    "- Busca información sobre \"Task Decomposition\"\n",
    "- Investiga extensiones del método encontrado\n",
    "- Streaming de respuesta en tiempo real\n",
    "- Trazabilidad del razonamiento del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3271f82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Multi-paso: What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "\n",
      "================================================================================\n",
      "Streaming activado...\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_eeU52UMAQPhdfqfCgZ9FVGuL)\n",
      " Call ID: call_eeU52UMAQPhdfqfCgZ9FVGuL\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Metadata: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578.0}\n",
      "Texto: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Metadata: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578.0}\n",
      "Texto: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_CYxbxsUV1MZ9LE9873uTDslG)\n",
      " Call ID: call_CYxbxsUV1MZ9LE9873uTDslG\n",
      "  Args:\n",
      "    query: extensions of task decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Metadata: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578.0}\n",
      "Texto: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Metadata: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578.0}\n",
      "Texto: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The standard method for task decomposition involves several approaches:\n",
      "\n",
      "1. **LLM with Simple Prompting**: Using language model prompts to break down tasks, for example asking \"What are the subgoals for achieving XYZ?\" This method relies on generating a list or sequence of sub-tasks from a main task prompt.\n",
      "\n",
      "2. **Task-Specific Instructions**: Providing specific instructions tailored to the task at hand, like giving a prompt to \"Write a story outline\" when tasked with writing a novel.\n",
      "\n",
      "3. **Human Inputs**: Using human judgment and expertise to outline and decompose tasks into manageable sub-tasks.\n",
      "\n",
      "Beyond these methods, there is a more complex approach known as **LLM+P (Liu et al. 2023)**. This involves using an external classical planner for long-horizon planning. The process leverages the Planning Domain Definition Language (PDDL):\n",
      "- Translating the task problem into a \"Problem PDDL\".\n",
      "- Requesting a classical planner to generate a PDDL plan based on a \"Domain PDDL\".\n",
      "- Translating the PDDL plan back into natural language.\n",
      "\n",
      "This method outsources the planning step to an external tool, leveraging domain-specific PDDL and a suitable planner, which is especially common in certain robotics-related applications.\n",
      "\n",
      "These approaches can be complemented by extensions that adapt task decomposition methods for specific applications, environments, or technologies such as robotic setups or domain-specific tasks.\n"
     ]
    }
   ],
   "source": [
    "multi_step_query = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "print(f\"Query Multi-paso: {multi_step_query}\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"Streaming activado...\\n\")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": multi_step_query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684d6baf",
   "metadata": {},
   "source": [
    "## 4. Test de Validación\n",
    "\n",
    "Verificación con pregunta directa para evaluar respuestas básicas del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7c601e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Directa: What is task decomposition?\n",
      "\n",
      "================================================================================\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is task decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_3q01DOy2E3d88ODtnHOUuKV9)\n",
      " Call ID: call_3q01DOy2E3d88ODtnHOUuKV9\n",
      "  Args:\n",
      "    query: task decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Metadata: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578.0}\n",
      "Texto: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Metadata: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578.0}\n",
      "Texto: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is the process of breaking down a complex task into smaller, more manageable sub-tasks or steps. This can be achieved using different methods, such as:\n",
      "\n",
      "1. **Simple Prompting with Large Language Models (LLM):** By asking questions like \"What are the steps for achieving XYZ?\" or \"What are the subgoals for achieving XYZ?\", LLMs can help outline the necessary steps.\n",
      "\n",
      "2. **Task-Specific Instructions:** Providing explicit instructions related to the task, such as \"Write a story outline\" for writing a novel, can also guide the decomposition process.\n",
      "\n",
      "3. **Human Inputs:** Involving human judgment and expertise can contribute significantly to the decomposition of tasks.\n",
      "\n",
      "A more advanced approach, LLM+P, involves external classical planners for long-horizon planning. This method uses the Planning Domain Definition Language (PDDL) to describe the problem. The steps include translating the problem into a PDDL format, using a classical planner to create a plan, and then translating the plan back into natural language. This method is widely used in domains like robotics where domain-specific PDDL and planners are available.\n"
     ]
    }
   ],
   "source": [
    "simple_query = \"What is task decomposition?\"\n",
    "\n",
    "print(f\"Query Directa: {simple_query}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": simple_query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0597dd",
   "metadata": {},
   "source": [
    "## 5. Inspección del Índice\n",
    "\n",
    "Revisión del estado del vector store post-indexación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3c19be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado del Vector Store:\n",
      "================================================================================\n",
      "     Índice: arep\n",
      "     Dims: 1024\n",
      "     Vectores: 126\n",
      "     Similitud: cosine\n",
      "     Infraestructura: serverless (AWS us-east-1)\n",
      "\n",
      "Test de búsqueda OK\n",
      "Query: 'AI agents'\n",
      "Matches: 1\n",
      "Preview: They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agen...\n"
     ]
    }
   ],
   "source": [
    "# Consultar estadísticas actuales\n",
    "final_stats = pc_index.describe_index_stats()\n",
    "\n",
    "print(\"Estado del Vector Store:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"     Índice: {idx_name}\")\n",
    "print(f\"     Dims: {final_stats.get('dimension', 'N/A')}\")\n",
    "print(f\"     Vectores: {final_stats.get('total_vector_count', 0):,}\")\n",
    "print(f\"     Similitud: cosine\")\n",
    "print(f\"     Infraestructura: serverless (AWS us-east-1)\")\n",
    "# Test de búsqueda\n",
    "probe_query = \"AI agents\"\n",
    "probe_results = vector_db.similarity_search(probe_query, k=1)\n",
    "print(f\"\\nTest de búsqueda OK\")\n",
    "print(f\"Query: '{probe_query}'\")\n",
    "print(f\"Matches: {len(probe_results)}\")\n",
    "if probe_results:\n",
    "    print(f\"Preview: {probe_results[0].page_content[:150]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
